This repository contains representative scripts that I wrote when working on the project "Extraction of dialect features from North American news media". As part of this project I iterated over news media databases in search of tokens of dialect constructions. Some of the results of the project have been published in the form of interactive dialect maps: http://yerastov.fhsu.edu/maps.html.

This repository is structured as follows. The directory "web_scraping" contains scripts used to (1) send a query to the database server, (2) extract a list of URLs pointing to relevant news media resources, and (3) capture dialect tokens from those resources. The directory "extraction" contains scripts used to identify relevant sentences and exclude false positives by using NLP methods such as tagging and chunking. The directory "data processing" contains various scripts for sorting, merging, geocoding, and cleaning datasets.
